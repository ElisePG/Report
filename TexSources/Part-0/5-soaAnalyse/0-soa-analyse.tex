\todo[inline]{Verantwortlich: Jonas}

Die Detektion von Emotionen kann auf unterschiedlichste Art erfolgen. In der Literatur wird neben der Verarbeitung von Biosignalen mittlerweile häufig auf eine Detektion durch Kameras oder durch die Analyse von Sprache gesetzt.(vgl. \cite{}) \\

Die Analyse mittels einer Kamera und der Aufnahme von Gesichtsmimik oder Augenbewegung war in der vorliegenden Arbeit nicht möglich, da die HTC Vive die der Proband während des Experimentes trägt, einen Großteil des Gesichtes und damit die Mimik wie auch die Augen verdeckt. Eine Interaktion mit dem Probanden mittels Sprache war ebenfalls nicht vorgesehen. Dementsprechend blieb nur die Möglichkeit der Detektion von Emotionen mittels Biosignalen. Hierbei wird in der Literatur vor allem die Atemfrequenz, die Hautleitfähigkeit, die elektrische Herzaktivität, die EEG Ableitung und die EOG Ableitung heran gezogen.(vgl. \cite{}) \\

Zur Klassifizierung der Emotionen werden in der Literatur unterschiedliche Techniken verwendet. In neuerer Zeit konzentriert sich die Forschung dabei auf Machine Learning gestützte Ansätze.(vgl. \cite{}) Dabei wird zwischen supervised und unsupervised Modellen unterschieden. Bei den unsupervised Modellen wird insbesondere Sequential Floating Forward Search und k-Nearest Neighbour (k-NN) benutzt. Hierbei handelt es sich um Techniken zur Selektion relevanter Features beziehungsweise zur Klassifizierung von Features durch Gruppenbildung.  Auf der Seite der supervised Modelle sticht vor allem die Nutzung der Support Vecotor Machine (SVM) hervor.(vgl. \cite{}) Hierbei wird wie bei allen supervised Modellen ein Datensatz mit Labels genutzt um das Modell auf die zugrunde liegende Datenmenge zu trainieren. 
