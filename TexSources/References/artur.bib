@inproceedings{bettadapura2012,
  author       = {V. Bettadapura},
  title        = {Face Expression Recognition and Analysis, The State of the Art},
  year         = {2012},
  month        = {March},
  booktitle    = {},}


@article{tian2001,
  author  = {Y.I. Tian and T. Kanade and J.F. Cohn}, 
  title   = {Recognizing Action Units for Facial Expression Analysis},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2001},
  number  = {issue 2},
  pages   = {pages 97-–115},
  month   = {February},
  volume  = {volume 23},}


@article{michel_and_kaliouby2003,
  author       = {P. Michel and R. Kaliouby},
  title        = {Real Time Facial Expression Recognition in Video Using Support Vector Machines},
  journal      = {Proceedings of the 5th international conference on Multimodal interfaces},
  year         = {2003},
  number       = {},
  pages        = {258--264},
  month        = {November},
  volume       = {},}


@article{sinith_ieee_2015,
  author  = {M.S. Sinith and E. Aswathi and T.M. Deepa and C.P. Shameemaet and S. Rajan}, 
  title   = {Emotion recognition from audio signals using Support Vector Machine},
  journal = {IEEE Recent Advances in Intelligent Computational Systems (RAICS)},
  year    = {2015},
  number  = {},
  pages   = {},
  month   = {December},
  volume  = {},}


@article{martinez_ieee_2013,
  author  = {H.P. Martinez and Y. Bengio and G.N. Yannakakis}, 
  title   = {Learning deep physiological models of affect},
  journal = {IEEE Computational Intelligence Magazine},
  year    = {2013},
  number  = {issue 2},
  pages   = {pages 20--33},
  month   = {April},
  volume  = {volume 8},}


@book{yannakakis_2010,
  author    = {G.N. Yannakakis and H.P. Martinez and Arnav Jhala}, 
  title     = {User Modeling and User-Adapted Interaction: Towards affective camera control in games},
  publisher = {Springer Netherlands},
  year      = {2010},
  volume    = {20(issue 4)},
  pages     = {pages 313--340},
  month     = {October},}


@article{optical_flow2015,
  author  = {P. Fischer and A. Dosovitskiy and E. Ilg and P. Haeusser and C. Hazirbas and V. Golkov and P. Smagt and D. Cremers and T. Brox}, 
  title   = {Learning Optical Flow with Convolutional Networks},
  journal = {},
  year    = {2015},
  number  = {},
  pages   = {},
  month   = {April},
  volume  = {},}


@article{gabor_wavelets1996,
  author  = {T.S. Lee}, 
  title   = {Image Representation Using 2D Gabor Wavelets},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {1996},
  number  = {issue 10},
  pages   = {pages 959--971},
  month   = {October},
  volume  = {volume 18},}
  
  
@article{multistate_model2004,
  author  = {G. Ferretti and G. Magnani and P. Rocco}, 
  title   = {Single and multistate integral friction models},
  journal = {IEEE Transactions on Automatic Control},
  year    = {2004},
  number  = {issue 12},
  pages   = {pages 2292--2297},
  month   = {December},
  volume  = {volume 49},}
  

@article{canny_edge_detection_1986,
  author  = {J. Canny}, 
  title   = {A Computational Approach to Edge Detection},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {1986},
  number  = {issue 6},
  pages   = {pages 679--698},
  month   = {November},
  volume  = {volume PAMI-8},}


@book{svn1995,
    author = {C. Cortes and V. Vapnik},
    title = {Support-Vector Networks},
    publisher = {Kluwer Academic Publishers, Boston},
    volume = {volume 20},
    number = {issue 3},
    year = {1995},
    month = {September},}


@inproceedings{kernel_2013,
  author       = {E. Kim},
  title        = {Everything You Wanted to Know about the Kernel Trick},
  year         = {2013},
  month        = {September},
  booktitle    = {},}


@article{kimiaki_codebook_approach_2016,
  author  = {K. Shirahama and L. Koeping and M. Grzegorzek}, 
  title   = {Codebook approach for sensor-based human activity recognition},
  journal = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  year    = {2016},
  number  = {},
  pages   = {197--200},
  month   = {September},
  volume  = {},}
  

@article{gemert_ieee_2009,
  author  = {J.C. van Gemert and C.J. Veenman and A.W.M. Smeulders}, 
  title   = {Visual Word Ambiguity},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2009},
  number  = {issue 7},
  pages   = {pages 1271--1283},
  month   = {June},
  volume  = {volume 32},}


@book{murphy_2012,
    author = {K.P. Murphy},
    title = {Machine Learning and A Probabilistic Perspective},
    publisher = {The MIT Press, London},
    volume = {},
    number = {},
    year = {2012},
    month = {September},}


@article{snoek_2005,
  author  = {C.G.M. Snoek and M. Worring and A.W.M. Smeulders}, 
  title   = {Early versus late fusion in semantic video analysis},
  journal = {Proceedings of the 13th annual ACM international conference on Multimedia},
  year    = {2005},
  number  = {},
  pages   = {399--402},
  month   = {November},
  volume  = {},}


@book{bscGouverneur,
    author = {P. Gouverneur},
    title  = {Bachelor-thesis: Classification of physiological data for emotion recognition},
    year   = {2016},
    month  = {September},}


@book{bscpiet,
    author = {A. Piet},
    title  = {Bachelor-thesis: Emotion recognition using 1D physiological signals following a supervised learning approach},
    year   = {2017},
    month  = {December},}

@book{bsclittau,
    author = {J. Littau},
    title  = {Bachelor-thesis: Analysis of fourier features for emotion recognition using physiological signals},
    year   = {2018},
    month  = {June},}

@book{grus15,
    author    = {J. Grus},
    title     = {Data Science from Scratch},
    publisher = {O'Reilly Media},
    year = {2015},
    month = {April},}


@misc{elise_logo,
    author = "{A. Paultre, Limbic Entarteinment GmbH}",
    title = "{Logo of the project ELISE}"}


@misc{basic_emotions_theories,
    author       = "{T. Goschke}",
    title        = "{Emotionspsychologie I}",
    year         = "{accessed on 19 November 2017}",
    howpublished = {\url{https://tu-dresden.de/mn/psychologie/allgpsy/ressourcen/dateien/lehre/lehreveranstaltungen/goschke_lehre/ws_2013/vl_motivation/VL-Emotion-1.pdf?lang=de}}}
    

@article{Plutchik_2001, 
    author = {R. Plutchik}, 
    title = {The Nature of Emotions}, 
    journal = {American Scientist}, 
    volume = {volume 89}, 
    year = {2001}, 
    number = {}, 
    month = {}, 
    pages = {page 334} }
    
    
@article{russel_1980, 
    author = {J. Russel}, 
    title = {A Circumplex Model of Affect}, 
    journal = {Journal of Personality and Social Psychology}, 
    volume = {volume 39}, 
    year = {1980}, 
    number = {issue 6}, 
    month = {}, 
    pages = {pages 1161--1178}}
    
    
@article{ekman_1999, 
    author = {P. Ekman}, 
    title = {Facial Expressions}, 
    journal = {Handbook of Cognition and Emotion}, 
    volume = {}, 
    year = {1999}, 
    number = {}, 
    month = {}, 
    pages = {301--320} }   


@article{vodanovich_2003, 
    author = {S. J. Vodanovich}, 
    title = {Psychometric measures of boredom: A review of the literature}, 
    journal = {Journal of Psychology}, 
    volume = {volume 137}, 
    year = {2003}, 
    number = {issue 6}, 
    month = {November}, 
    pages = {pages 569--595}} 


@article{fehr_russel_1984, 
    author = {B. Fehr and J. A. Russel}, 
    title = {Concept of emotion viewed from a prototype perspective}, 
    journal = {Journal of Experimental Psychology: General}, 
    volume = {volume 113}, 
    year = {1984}, 
    number = {issue 3}, 
    month = {}, 
    pages = {pages 464--486}} 

    
@misc{Zhu2008,
    author = {X. Zhu},
    title  = {Semi-Supervised Learning Literature Survey},
    year   = {2008},
    month  = {July},}


@misc{gault-questionnaire,
    author       = "{R. H. Gault}",
    title        = "{A history of the questionnaire method of research in psychology}",
    year         = "{accessed on 30 January 2019}",
    howpublished = {\url{https://www.tandfonline.com/doi/abs/10.1080/08919402.1907.10532551}}}


@book{plamper12,
    author    = {J. Plamper},
    title     = {Geschichte und Gefühl: Grundlagen der Emotionsgeschichte},
    publisher = {Siedler},
    year = {2012},
    month = {November},}


@book{geslin13,
    author    = {E. Geslin},
    title     = {Processus d’induction d’émotions dans les environnements virtuels et le jeu vidéo},
    publisher = {Psychologie},
    year = {2013},
    month = {},}


@book{darwin1872,
    author    = {C. Darwin},
    title     = {Der Ausdruck der Gemütsbewegungen bei dem Menschen und den Tieren},
    publisher = {},
    year = {1872},
    month = {November},}


@misc{james1884,
    author       = "{W. James}",
    title        = "{What Is an Emotion?}",
    year         = "{letzter Zugriff am 8. März 2019}",
    howpublished = {\url{https://www.scirp.org/(S(351jmbntvnsjt1aadkposzje))/reference/ReferencesPapers.aspx?ReferenceID=1331721}}}


@misc{cannon32,
    author       = "{W. B. Cannon}",
    title        = "{The Wisdom of the Body}",
    year         = "{letzter Zugriff am 8. März 2019}",
    howpublished = {\url{https://www.scirp.org/(S(351jmbntvnsjt1aadkposzje))/reference/ReferencesPapers.aspx?ReferenceID=1533450}}}


@misc{schachter59,
    author       = "{S. Schachter}",
    title        = "{The psychology of affiliation}",
    year         = "{letzter Zugriff am 8. März 2019}",
    howpublished = {\url{https://journals.sagepub.com/doi/abs/10.1177/002076406100700316}}}


@misc{kolb18,
    author       = "{A. Kolb}",
    title        = "{Virtual Reality Introduction}",
    year         = "{letzter Zugriff am 8. März 2019}",
    howpublished = {\url{http://www.cg.informatik.uni-siegen.de/sites/www.cg.informatik.uni-siegen.de/files/Dateianhaenge/vr-part01-script_3.pdf}}}


@misc{vive19,
    author       = "{HTC Corporation}",
    title        = "{VIVE VR-SYSTEM}",
    year         = "{letzter Zugriff am 9. März 2019}",
    howpublished = {\url{https://www.vive.com/de/product/}}}


@misc{bien19,
    author       = "{G. Bien}",
    title        = "{Über das Glück}",
    year         = "{letzter Zugriff am 5. März 2019}",
    howpublished = {\url{http://www.joachimschummer.net/books/glueck-und-ethik/bien.pdf}}}


@misc{sun360,
    author       = "{J. Xiao and K. A. Ehinger and A. Oliva and A. Torralba}",
    title        = "{Recognizing Scene Viewpoint using Panoramic Place Representation}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://people.csail.mit.edu/jxiao/SUN360/}}}


@misc{facerig19,
    author       = "{Coldacid}",
    title        = "{Adding custom cube backgrounds}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://steamcommunity.com/sharedfiles/filedetails/?id=589533498}}}


@misc{dateiendungen19,
    author       = "{V. Oberst}",
    title        = "{.dds Dateiendung}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://www.dateiendung.com/format/dds}}}


@misc{franczak19,
    author       = "{M. Franczak}",
    title        = "{Creating custom sky from HDR image in Unreal Engine}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://evermotion.org/tutorials/show/10738/creating-custom-sky-from-hdr-image-in-unreal-engine}}}


@misc{belanec19,
    author       = "{M. Belanec}",
    title        = "{GLSL cube mapping}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{http://www.3dcpptutorials.sk/index.php?id=24}}}


@misc{eizo19,
    author       = "{M. Kontani and Y. Jitsumori}",
    title        = "{HDR im Detail – was ist HDR?}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://www.eizo.de/praxiswissen/monitorwissen/hdr-im-detail-was-ist-hdr/}}}


@misc{finch19,
    author       = "{G. Finch}",
    title        = "{What is HDR? HDR vs. SDR compared}",
    year         = "{letzter Zugriff am 12. März 2019}",
    howpublished = {\url{https://www.viewsonic.com/library/photography/what-is-hdr-hdr-vs.-sdr}}}


@book{msckroenert,
    author = {D. Krönert},
    title  = {Entwurf eines kompakten mikrocontrollergestützten Systemszur Emotionserkennung in einer Virtual-Reality-Umgebung},
    year   = {2017},
    month  = {},}


@book{zeiler12,
    author = {M. D. Zeiler},
    title  = {ADADELTA: An adaptive learning rate methode},
    year   = {2012},
    month  = {Decemer},}


@article{nair12, 
    author = {V. Nair and G. E. Hinton}, 
    title = {Rectified linear units improve restricted boltzmann machines}, 
    journal = {ICML'10 Proceedings of the 27th International Conference on Machine Learning}, 
    volume = {}, 
    year = {2012}, 
    number = {}, 
    month = {June}, 
    pages = {pages 807--814}} 


@book{bscschnieber18,
    author = {K. Schnieber},
    title  = {Bachelor-thesis: Processing and analysis of sensor data in the context of emotion recognition},
    year   = {2018},
    month  = {},}


@article{hochreiter97, 
    author = {S. Hochreiter and J. Schmidhuber}, 
    title = {Long shirt-term memory}, 
    journal = {Neural Computation}, 
    volume = {volume 9}, 
    year = {1997}, 
    number = {issue 8}, 
    month = {November}, 
    pages = {pages 1735--1780}}
    
@article{soa01,
  author    = {Armin Seyeditabari and
               Narges Tabari and
               Wlodek Zadrozny},
  title     = {Emotion Detection in Text: a Review},
  journal   = {CoRR},
  volume    = {abs/1806.00674},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.00674},
  archivePrefix = {arXiv},
  eprint    = {1806.00674},
  timestamp = {Mon, 13 Aug 2018 16:46:27 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-00674},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{soa2,
title = "Emotion Detection Using MFCC and Cepstrum Features",
journal = "Procedia Computer Science",
volume = "70",
pages = "29 - 35",
year = "2015",
note = "Proceedings of the 4th International Conference on Eco-friendly Computing and Communication Systems",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.10.020",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915031841",
author = "S. Lalitha and D. Geyasruti and R. Narayanan and Shravani M",
keywords = "Enlargement, MFCC, Cepstral coefficients, Neural Networks, Berlin Database",
abstract = "A tremendous research is being done on Speech Emotion Recognition (SER) in the recent years with its main motto to improve human machine interaction. In this work, the effect of cepstral coefficients in the detection of emotions is performed. Also, a comparative analysis of cepstum, Mel-frequency Cepstral Coefficients (MFCC) and synthetically enlarged MFCC coefficients on emotion classification is done. Using a compact feature vector, our algorithm depicted better recognition rates of identifying seven emotions from Berlin speech corpus compared to the earlier work by Firoz Shah where only four emotions were recognized with good accuracy. The proposed method has facilitated a considerable reduction in the misclassification efficiency which outperforms the algorithm by InmaMohino, where the feature vector included only synthetically enlarged MFCC coefficients."
}

@ARTICLE{soa3, 
author={P. {Chiranjeevi} and V. {Gopalakrishnan} and P. {Moogi}}, 
journal={IEEE Transactions on Image Processing}, 
title={Neutral Face Classification Using Personalized Appearance Models for Fast and Robust Emotion Detection}, 
year={2015}, 
volume={24}, 
number={9}, 
pages={2701-2711}, 
keywords={computer vision;emotion recognition;face recognition;image classification;image motion analysis;image texture;learning (artificial intelligence);object detection;neutral face classification;personalized appearance models;emotion detection;facial expression recognition;computer vision;supervised learning;appearance variability;key emotion points;KE points;statistical texture model;user head motions;affine distortion;ER accuracy;computational complexity;Shape;Face;Computational modeling;Erbium;Accuracy;Mouth;Robustness;Neutral Vs. emotion classification;Constrained Local Model;Key Emotion Points;Procrustes analysis;Local Binary Pattern Histogram;Statistical model;Structural similarity;Action units;Neutral vs. emotion classification;constrained local model;key emotion points;procrustes analysis;local binary pattern histogram;statistical model;structural similarity;action units;Algorithms;Biometric Identification;Databases, Factual;Emotions;Face;Facial Expression;Humans;Image Processing, Computer-Assisted;Models, Statistical}, 
doi={10.1109/TIP.2015.2421437}, 
ISSN={1057-7149}, 
month={Sep.},}

@INPROCEEDINGS{soa4, 
author={C. {Jain} and K. {Sawant} and M. {Rehman} and R. {Kumar}}, 
booktitle={2018 3rd International Conference and Workshops on Recent Advances and Innovations in Engineering (ICRAIE)}, 
title={Emotion Detection and Characterization using Facial Features}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={Support vector machines;Gabor filters;Discrete wavelet transforms;Face;Kernel;Feature extraction;Classification algorithms;Characterization;FacialExpression;Emotions;Cascade;Classification;SVM;Kernel;Grid Search;Wavelet;HOG;Precision}, 
doi={10.1109/ICRAIE.2018.8710406}, 
ISSN={}, 
month={Nov},}

@InProceedings{soa5,
author="Rincon, Jaime Andres
and Costa, {\^A}ngelo
and Novais, Paulo
and Julian, Vicente
and Carrascosa, Carlos",
editor="Gra{\~{n}}a, Manuel
and L{\'o}pez-Guede, Jos{\'e} Manuel
and Etxaniz, Oier
and Herrero, {\'A}lvaro
and Quinti{\'a}n, H{\'e}ctor
and Corchado, Emilio",
title="Using Non-invasive Wearables for Detecting Emotions with Intelligent Agents",
booktitle="International Joint Conference SOCO'16-CISIS'16-ICEUTE'16",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="73--84",
abstract="This paper proposes the use of intelligent wristbands for the automatic detection of emotional states in order to develop an application which allows to extract, analyze, represent and manage the social emotion of a group of entities. Nowadays, the detection of the joined emotion of an heterogeneous group of people is still an open issue. Most of the existing approaches are centered in the emotion detection and management of a single entity. Concretely, the application tries to detect how music can influence in a positive or negative way over individuals' emotional states. The main goal of the proposed system is to play music that encourages the increase of happiness of the overall patrons.",
isbn="978-3-319-47364-2"
}

@INPROCEEDINGS{soa6, 
author={P. {Rathod} and K. {George} and N. {Shinde}}, 
booktitle={2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN)}, 
title={Bio-signal based emotion detection device}, 
year={2016}, 
volume={}, 
number={}, 
pages={105-108}, 
keywords={emotion recognition;biosignal;emotion detection device;real-time emotion recognition;human-machine interaction;assistive technologies;education;medicine;heart rate;skin conductance sensors;facial expressions;audiovisual clips;Heart rate;Skin;Webcams;Biological system modeling;Biosensors}, 
doi={10.1109/BSN.2016.7516241}, 
ISSN={2376-8894}, 
month={June},}


@article{soa7,
title = "Reliable emotion recognition system based on dynamic adaptive fusion of forehead biopotentials and physiological signals",
journal = "Computer Methods and Programs in Biomedicine",
volume = "122",
number = "2",
pages = "149 - 164",
year = "2015",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2015.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0169260715001959",
author = "Mahdi Khezri and Mohammad Firoozabadi and Ahmad Reza Sharafat",
keywords = "Emotion recognition system, Dynamic adaptive fusion of classification units, Forehead bioelectric signals, Physiological signals, Human computer interactions",
abstract = "In this study, we proposed a new adaptive method for fusing multiple emotional modalities to improve the performance of the emotion recognition system. Three-channel forehead biosignals along with peripheral physiological measurements (blood volume pressure, skin conductance, and interbeat intervals) were utilized as emotional modalities. Six basic emotions, i.e., anger, sadness, fear, disgust, happiness, and surprise were elicited by displaying preselected video clips for each of the 25 participants in the experiment; the physiological signals were collected simultaneously. In our multimodal emotion recognition system, recorded signals with the formation of several classification units identified the emotions independently. Then the results were fused using the adaptive weighted linear model to produce the final result. Each classification unit is assigned a weight that is determined dynamically by considering the performance of the units during the testing phase and the training phase results. This dynamic weighting scheme enables the emotion recognition system to adapt itself to each new user. The results showed that the suggested method outperformed conventional fusion of the features and classification units using the majority voting method. In addition, a considerable improvement, compared to the systems that used the static weighting schemes for fusing classification units, was also shown. Using support vector machine (SVM) and k-nearest neighbors (KNN) classifiers, the overall classification accuracies of 84.7% and 80% were obtained in identifying the emotions, respectively. In addition, applying the forehead or physiological signals in the proposed scheme indicates that designing a reliable emotion recognition system is feasible without the need for additional emotional modalities."
}


@INPROCEEDINGS{soa8, 
author={J. {Perdiz} and G. {Pires} and U. J. {Nunes}}, 
booktitle={2017 IEEE 5th Portuguese Meeting on Bioengineering (ENBENG)}, 
title={Emotional state detection based on EMG and EOG biosignals: A short survey}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-4}, 
keywords={biomechanics;electromyography;electro-oculography;face recognition;medical signal processing;emotional state detection;EMG biosignals;EOG biosignals;muscular potential acquisition;facial electromyography;physiological signal;emotional expressions detection;computer vision-based facial recognition;electrooculographic signals;gaze tracking;eye movements;biosignal sources;facial expression detection;saccade detection;neutral expression;sad expression;happy expression;angry expression;Electromyography;Electrooculography;Electrodes;Feature extraction;Face recognition;Emotion recognition;Face}, 
doi={10.1109/ENBENG.2017.7889451}, 
ISSN={}, 
month={Feb},}


@Article{soa9,
author="Anagnostopoulos, Christos-Nikolaos
and Iliou, Theodoros
and Giannoukos, Ioannis",
title="Features and classifiers for emotion recognition from speech: a survey from 2000 to 2011",
journal="Artificial Intelligence Review",
year="2015",
month="Feb",
day="01",
volume="43",
number="2",
pages="155--177",
abstract="Speaker emotion recognition is achieved through processing methods that include isolation of the speech signal and extraction of selected features for the final classification. In terms of acoustics, speech processing techniques offer extremely valuable paralinguistic information derived mainly from prosodic and spectral features. In some cases, the process is assisted by speech recognition systems, which contribute to the classification using linguistic information. Both frameworks deal with a very challenging problem, as emotional states do not have clear-cut boundaries and often differ from person to person. In this article, research papers that investigate emotion recognition from audio channels are surveyed and classified, based mostly on extracted and selected features and their classification methodology. Important topics from different classification techniques, such as databases available for experimentation, appropriate feature extraction and selection methods, classifiers and performance issues are discussed, with emphasis on research published in the last decade. This survey also provides a discussion on open trends, along with directions for future research on this topic.",
issn="1573-7462",
doi="10.1007/s10462-012-9368-5",
url="https://doi.org/10.1007/s10462-012-9368-5"
}

@incollection{soa10,
title = "Chapter 5 - Measuring Emotions: A Survey of Cutting Edge Methodologies Used in Computer-Based Learning Environment Research",
editor = "Sharon Y. Tettegah and Martin Gartmeier",
booktitle = "Emotions, Technology, Design, and Learning",
publisher = "Academic Press",
address = "San Diego",
pages = "89 - 114",
year = "2016",
series = "Emotions and Technology",
isbn = "978-0-12-801856-9",
doi = "https://doi.org/10.1016/B978-0-12-801856-9.00005-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780128018569000050",
author = "Jason Matthew Harley",
keywords = "Emotion, Affect, Emotion measurement, Emotion recognition, Multimodal measurement, Computer-based learning environments",
abstract = "This review provides a contemporary, critical survey of the interdisciplinary methods used in research with computer-based learning environments (CBLEs) to measure learners’ emotions, including: facial expression coding, body posture and physiological measurement devices, log-file data, and self-report measures. Novel insights are provided and important issues pertaining to emotion measurement are revisited in light of new research, including: theoretical and analytical considerations; the effectiveness of multimethod (e.g., multimodal) approaches; and the potential use of different types of data for informing emotionally supportive CBLEs. Recommendations are also shared to assist researchers in improving their emotion measurement methodologies. This chapter was written with the educational psychology community in mind to help support a growing interest in alternative and complimentary methods to self-report measures. As such, this chapter stands to not only add to the existing interdisciplinary discussion on emotion measurement methods, but also to expand it to potentially new participants."
}

@INPROCEEDINGS{soa11, 
author={A. {Bhardwaj} and A. {Gupta} and P. {Jain} and A. {Rani} and J. {Yadav}}, 
booktitle={2015 2nd International Conference on Signal Processing and Integrated Networks (SPIN)}, 
title={Classification of human emotions from EEG signals using SVM and LDA Classifiers}, 
year={2015}, 
volume={}, 
number={}, 
pages={180-185}, 
keywords={electroencephalography;emotion recognition;independent component analysis;learning (artificial intelligence);signal classification;support vector machines;human emotion classification;EEG signal classification;SVM classifier;LDA classifier;emotion detection;human computer interface;electroencephalography signals;brain neuron electrical activity;independent component analysis;ICA;machine learning techniques;support vector machine;linear discriminant analysis;Electroencephalography;Accuracy;Support vector machines;Feature extraction;Brain modeling;Training;Electrodes;EEG;Emotion Detection;IAPS;ICA;LDA;Machine Learning;Neuro-marketing;SVM}, 
doi={10.1109/SPIN.2015.7095376}, 
ISSN={}, 
month={Feb},}

@INPROCEEDINGS{soa12, 
author={A. S. {Patwardhan}}, 
booktitle={2017 2nd International Conference on Communication and Electronics Systems (ICCES)}, 
title={Multimodal mixed emotion detection}, 
year={2017}, 
volume={}, 
number={}, 
pages={139-143}, 
keywords={audio signal processing;emotion recognition;face recognition;feature extraction;image classification;support vector machines;emotional duality;audio-visual continuous data;captured facial expressions;hand gesture;body movement;spectral features;prosodic features;audio channel;audio-visual data;depth information;infrared sensor;OpenEar toolkit;Face API;combined feature vector;feature level fusion;support vector machine based classifier;simultaneous mixed emotional experience;concurrent emotions;multimodal mixed emotion recognition;multimodal mixed emotion detection;Emotion recognition;Feature extraction;Tracking;Face;Support vector machines;Magnetic heads;Face recognition;Affect;Ambivalent;Audio;Concurrent;Emotion Duality;Mixed Emotion;Multimodal;Multiple;Recognition;Simultaneous Emotion;Temporal Features;Sensor}, 
doi={10.1109/CESYS.2017.8321250}, 
ISSN={}, 
month={Oct},}

@INPROCEEDINGS{soa13, 
author={U. {Jain} and K. {Nathani} and N. {Ruban} and A. N. {Joseph Raj} and Z. {Zhuang} and V. {G.V. Mahesh}}, 
booktitle={2018 International Conference on Sensor Networks and Signal Processing (SNSP)}, 
title={Cubic SVM Classifier Based Feature Extraction and Emotion Detection from Speech Signals}, 
year={2018}, 
volume={}, 
number={}, 
pages={386-391}, 
keywords={cepstral analysis;emotion recognition;feature extraction;natural language processing;pattern classification;speech processing;speech recognition;support vector machines;artificial intelligence;emotion identification;Hindi language speech;noisy environment;acoustic signal;speech emotion detection;cubic SVM classifier;feature extraction;speech signals;mel-frequency cepstrum coefficients;linear prediction cepstral coefficient;cubic spine support vector machine classifier model;Feature extraction;Support vector machines;Databases;Speech recognition;Emotion recognition;Principal component analysis;Cepstral analysis;Mel-frequency Cepstrum Coefficients (MFCC);Linear Prediction Cepstral Coefficient (LPCC);Speech recognition;Emotion identifier;Support Vector Machine (SVM);Principal Component Analysis (PCA)}, 
doi={10.1109/SNSP.2018.00081}, 
ISSN={}, 
month={Oct},}






